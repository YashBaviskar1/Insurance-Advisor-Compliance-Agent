# app2.py
import streamlit as st
from langchain_groq import ChatGroq
from langchain_core.prompts import PromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains.retrieval import create_retrieval_chain
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
GROQ_API_KEY = os.environ.get("GROQ_API_KEY")

# Initialize session state
if "user_profile" not in st.session_state:
    st.session_state.user_profile = {}
if "qa_chain" not in st.session_state:
    st.session_state.qa_chain = None

# Load vector store
@st.cache_resource
def load_vector_store():
    DB_PATH = "vectorstore/db_faiss_beema"
    embedding_model = HuggingFaceEmbeddings(model_name="BAAI/bge-base-en-v1.5")
    return FAISS.load_local(DB_PATH, embedding_model, allow_dangerous_deserialization=True)

# Initialize QA chain
def init_qa_chain(language="hindi"):
    # Load LLM with language-specific model
    groq_model = "meta-llama/llama-4-scout-17b-16e-instruct"  # Supports Hindi
    
    llm = ChatGroq(
        temperature=0.3,
        groq_api_key=GROQ_API_KEY,
        model_name=groq_model
    )
    
    # Language-specific instructions
    lang_instruction = {
        "hindi": "рдХреЗрд╡рд▓ рд╣рд┐рдВрджреА рдореЗрдВ рдЙрддреНрддрд░ рджреЗрдВред рд╕рднреА рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛рдПрдБ рд╣рд┐рдВрджреА рдореЗрдВ рд╣реЛрдиреА рдЪрд╛рд╣рд┐рдПред",
        "english": "Respond only in English. All answers must be in English."
    }
    
    # Custom prompt with user profile and language
    PROMPT_TEMPLATE = f"""
    рдЖрдк рдПрдХ рдмреАрдорд╛ рд╕рд▓рд╛рд╣рдХрд╛рд░ рд╣реИрдВред рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдХреЗ рдкреНрд░рд╢реНрди рдХрд╛ рд╕рдВрджрд░реНрдн рдФрд░ рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдкреНрд░реЛрдлрд╝рд╛рдЗрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЙрддреНрддрд░ рджреЗрдВред
    
    {lang_instruction[language]}
    
    рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдкреНрд░реЛрдлрд╝рд╛рдЗрд▓:
    {st.session_state.user_profile}
    
    рд╕рдВрджрд░реНрдн:
    {{context}}
    
    рдкреНрд░рд╢реНрди:
    {{input}}
    
    рд╡рд┐рд╕реНрддреГрдд рдФрд░ рд╕рдЯреАрдХ рдЙрддреНрддрд░ рджреЗрдВред рдХреЗрд╡рд▓ рд╕рдВрджрд░реНрдн рдореЗрдВ рджреА рдЧрдИ рдЬрд╛рдирдХрд╛рд░реА рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред
    """
    
    prompt = PromptTemplate(
        template=PROMPT_TEMPLATE,
        input_variables=["context", "input"]
    )
    
    # Create QA chain
    db = load_vector_store()
    retriever = db.as_retriever(search_kwargs={'k': 3})
    qa_document_chain = create_stuff_documents_chain(llm, prompt)
    return create_retrieval_chain(retriever, qa_document_chain)

# User profile form
def user_profile_form():
    with st.form("user_profile_form"):
        st.subheader("ЁЯСд рдЕрдкрдирд╛ рд╡рд┐рд╡рд░рдг рджрд░реНрдЬ рдХрд░реЗрдВ")
        
        col1, col2 = st.columns(2)
        age = col1.number_input("рдЙрдореНрд░", min_value=18, max_value=100, value=35)
        income = col2.selectbox("рд╡рд╛рд░реНрд╖рд┐рдХ рдЖрдп", 
                              ["< тВ╣5 рд▓рд╛рдЦ", "тВ╣5-10 рд▓рд╛рдЦ", "тВ╣10-20 рд▓рд╛рдЦ", "> тВ╣20 рд▓рд╛рдЦ"])
        
        dependents = st.multiselect("рдЖрд╢реНрд░рд┐рдд (рдкрд░рд┐рд╡рд╛рд░ рдХреЗ рд╕рджрд╕реНрдп)", 
                                  ["рдЬреАрд╡рдирд╕рд╛рдереА", "рдмрдЪреНрдЪреЗ", "рдорд╛рддрд╛-рдкрд┐рддрд╛", "рдЕрдиреНрдп"])
        
        assets = st.multiselect("рд╕рдВрдкрддреНрддрд┐", 
                              ["рдШрд░", "рдХрд╛рд░", "рдЬрдореАрди", "рд╡реНрдпрд╡рд╕рд╛рдп"])
        
        health = st.selectbox("рд╕реНрд╡рд╛рд╕реНрдереНрдп рд╕реНрдерд┐рддрд┐", 
                            ["рдЙрддреНрдХреГрд╖реНрдЯ", "рдЕрдЪреНрдЫрд╛", "рдЙрдЪреНрдЪ рд░рдХреНрддрдЪрд╛рдк", "рдордзреБрдореЗрд╣", "рд╣реГрджрдп рд░реЛрдЧ"])
        
        location = st.selectbox("рд╕реНрдерд╛рди", 
                              ["рдореБрдВрдмрдИ", "рджрд┐рд▓реНрд▓реА", "рдЪреЗрдиреНрдирдИ", "рдмреИрдВрдЧрд▓реЛрд░", "рдХреЛрд▓рдХрд╛рддрд╛", "рд╣реИрджрд░рд╛рдмрд╛рдж"])
        
        language = st.radio(
    "рднрд╛рд╖рд╛", 
    ["hindi", "english"], 
    format_func=lambda x: "рд╣рд┐рдВрджреА" if x=="hindi" else "рдЕрдВрдЧреНрд░реЗрдЬреА"
)
        
        if st.form_submit_button("рдкреНрд░реЛрдлрд╝рд╛рдЗрд▓ рд╕рд╣реЗрдЬреЗрдВ"):
            st.session_state.user_profile = {
                "age": age,
                "income": income,
                "dependents": dependents,
                "assets": assets,
                "health": health,
                "location": location,
                "language": language.lower()
            }
            st.success("рдкреНрд░реЛрдлрд╝рд╛рдЗрд▓ рд╕рдлрд▓рддрд╛рдкреВрд░реНрд╡рдХ рд╕рд╣реЗрдЬреА рдЧрдИ!")
            st.session_state.qa_chain = init_qa_chain(language.lower())

# Main QA interface
def qa_interface():
    st.subheader("тЭУ рдЕрдкрдиреЗ рдмреАрдорд╛ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдкреВрдЫреЗрдВ")
    
    # Initialize QA chain if not done
    if st.session_state.qa_chain is None:
        st.session_state.qa_chain = init_qa_chain(
            st.session_state.user_profile.get("language", "hindi")
        )
    
    # Display user profile
    if st.session_state.user_profile:
        with st.expander("рдЖрдкрдХреА рдкреНрд░реЛрдлрд╝рд╛рдЗрд▓"):
            st.json(st.session_state.user_profile)
    
    # Question input
    question = st.text_area("рдЕрдкрдирд╛ рдкреНрд░рд╢реНрди рджрд░реНрдЬ рдХрд░реЗрдВ:", 
                          placeholder="рдореЗрд░реЗ рд╕реНрд╡рд╛рд╕реНрдереНрдп рдмреАрдорд╛ рдореЗрдВ рдЕрд╕реНрдкрддрд╛рд▓ рдореЗрдВ рднрд░реНрддреА рд╣реЛрдиреЗ рдХреА рдЕрд╡рдзрд┐ рдХреНрдпрд╛ рд╣реИ?")
    
    if st.button("рдЙрддреНрддрд░ рдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдВ") and question:
        with st.spinner("рдЖрдкрдХреЗ рдкреНрд░рд╢реНрди рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд┐рдпрд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИ..."):
            try:
                response = st.session_state.qa_chain.invoke({"input": question})
                st.subheader("рдЙрддреНрддрд░:")
                st.markdown(f"<div style='background-color:#f0f2f6; padding:20px; border-radius:10px;'>{response['answer']}</div>", 
                           unsafe_allow_html=True)
                
                # Show context sources
                with st.expander("рд╕рдВрджрд░реНрдн рд╕реНрд░реЛрдд рджреЗрдЦреЗрдВ"):
                    for i, doc in enumerate(response["context"]):
                        st.caption(f"рд╕реНрд░реЛрдд {i+1}:")
                        st.text(doc.page_content[:500] + "...")
            except Exception as e:
                st.error(f"рддреНрд░реБрдЯрд┐: {str(e)}")

# Main app
def main():
    st.set_page_config(page_title="рднрд╛рд░рдд рдмреАрдорд╛ рд╕рд╣рд╛рдпрдХ", page_icon="ЁЯЫбя╕П")
    st.title("ЁЯЫбя╕П рднрд╛рд░рдд рдмреАрдорд╛ рд╕рд╣рд╛рдпрдХ")
    st.caption("AI-рдкрд╛рд╡рд░реНрдб рдмреАрдорд╛ рд╕рд▓рд╛рд╣рдХрд╛рд░ рдЬреЛ рднрд╛рд░рддреАрдп рд╕рд░рдХрд╛рд░реА рдпреЛрдЬрдирд╛рдУрдВ рдХреА рд╡реНрдпрд╛рдЦреНрдпрд╛ рдХрд░рддрд╛ рд╣реИ")
    
    # Initialize vector store
    try:
        load_vector_store()
    except:
        st.error("рд╡реЗрдХреНрдЯрд░ рд╕реНрдЯреЛрд░ рд▓реЛрдб рдХрд░рдиреЗ рдореЗрдВ рддреНрд░реБрдЯрд┐ред рдХреГрдкрдпрд╛ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдЖрдкрдиреЗ рдкреАрдбреАрдПрдлрд╝ рдЗрдирдЬреЗрд╕реНрдЯ рдХрд┐рдпрд╛ рд╣реИ")
        return
    
    # Show user profile form if not completed
    if not st.session_state.user_profile:
        user_profile_form()
    else:
        if st.button("рдкреНрд░реЛрдлрд╝рд╛рдЗрд▓ рд╕рдВрдкрд╛рджрд┐рдд рдХрд░реЗрдВ"):
            st.session_state.user_profile = {}
            st.rerun()
        qa_interface()

if __name__ == "__main__":
    main()